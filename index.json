[{"authors":"admin","categories":null,"content":"I am holding a master\u0026rsquo;s degree in Social and Economic Data Science and just handed in my master thesis for the M.Sc. in Psychology. My interests are in the field of Cognitive Neuroscience, with a focus on neurodegenerative diseases. I enjoy learning in interdisciplinary work and the various research methods that come with it. Open science and reproducible documentation are key goals to my work, as it is fundamentally based on open source software.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jadenecke.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am holding a master\u0026rsquo;s degree in Social and Economic Data Science and just handed in my master thesis for the M.Sc. in Psychology. My interests are in the field of Cognitive Neuroscience, with a focus on neurodegenerative diseases. I enjoy learning in interdisciplinary work and the various research methods that come with it. Open science and reproducible documentation are key goals to my work, as it is fundamentally based on open source software.","tags":null,"title":"Jannis Denecke","type":"authors"},{"authors":null,"categories":["MRI","Linux","VM"],"content":"\r\rThis post is a summary of my experiences and difficulties with setting up MINC under WSL. MINC is a set of open-source tools for processing MRI files. It is developed at the McConnell Brain Imaging Centre, Montreal Neurological Institute (http://bic-mni.github.io/). In order to run it on a Windows machine, one needs to set up a virtual machine (VM), in my case an Ubuntu distribution. In the following, I will provide the steps and resources required to have a convenient setup using the Windows Subsystem for Linux (WSL) 2.\nInstalling WSL 2:\rMicrosoft provides a detailed step-by-step tutorial for this:\r- German: https://docs.microsoft.com/de-de/windows/wsl/install-win10\r- English: https://docs.microsoft.com/en-us/windows/wsl/install-win10\nPlease make sure to follow closely and also check the “Troubleshooting installation” section. I experienced two errors, one related to a visualization setting in the BIOS, the other regarding folder compression. Both (and some more) are explained in the troubleshooting section of the Microsoft article.\n\rInstalling MobaXterm:\rYou need to set up an X11 server to on your windows machine to access the graphical interface of MINC. I recommend MobaXterm, but there are other tools available:\n\rhttps://mobaxterm.mobatek.net/\r\rDownload, install, and launch the software. The X11 server should be already running when you launch the software, indicated by the colored X symbol in the upper right hand corner. The software should also automatically detect your Ubuntu distribution. You can open a terminal to your Ubuntu VM and it will start the VM, even when it is stopped. You will need the terminal to carry out the next step.\n\rInstalling MINC:\rThe full details are documented here, depending on the choice of your operating system:\n\rhttp://bic-mni.github.io/\r\rYou can download the files with windows, as the VM has read-access to your windows files (under /mnt/). You can also download the files with curl in your VM.\n\rSet Launch options:\rThere are two commands that I would like to execute on every launch with this VM:\nFirst, you need to set the X11 display address on your VM:\n\rexport DISPLAY=\"$(/sbin/ip route | awk '/default/ { print $3 }'):0\"\r\rSecond, you need to source the MINC config. I think this is because it uses some common names and you don’t want to have them sourced all the time. Since this is a one purpose VM (MINC), we can source the toolbox at startup:\n\rsource /opt/minc/1.9.18/minc-toolkit-config.sh for bash\rsource /opt/minc/1.9.18/minc-toolkit-config.csh for tcsh\r\rTo add these commands to your launch options of your VM, right-click the WSL-Ubuntu (differs for other OSs) session in MobaXterm and select “Edit Session”. Next, select the “Advanced WSL settings” tab and add the commands to the startup routine.\n\rWrap up:\rClose your open terminals and start a fresh one for your VM. Check whether e.g. the Display command works for you and the X11 transmission works properly. You might want to set the X11 remote access setting from “on-demand” to “full” in your MobaXterm settings if you want to avoid confirming the X11 session all the time.\n\r","date":1606176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606176000,"objectID":"663f30abe9aa80fd2ce62b29f45129e3","permalink":"https://jadenecke.github.io/2020/11/24/setup-of-the-minc-toolbox-medical-image-netcdf-with-wsl-2-windows-subsystem-for-linux-under-windows-10/","publishdate":"2020-11-24T00:00:00Z","relpermalink":"/2020/11/24/setup-of-the-minc-toolbox-medical-image-netcdf-with-wsl-2-windows-subsystem-for-linux-under-windows-10/","section":"post","summary":"This post is a summary of my experiences and difficulties with setting up MINC under WSL. MINC is a set of open-source tools for processing MRI files. It is developed at the McConnell Brain Imaging Centre, Montreal Neurological Institute (http://bic-mni.github.io/). In order to run it on a Windows machine, one needs to set up a virtual machine (VM), in my case an Ubuntu distribution. In the following, I will provide the steps and resources required to have a convenient setup using the Windows Subsystem for Linux (WSL) 2.","tags":["WSL","MINC","LINUX","VM"],"title":"Setup of the MINC toolbox (Medical Image NetCDF) with WSL 2 (Windows Subsystem for Linux) under Windows 10","type":"post"},{"authors":null,"categories":["R","NLP"],"content":"\rThis will merely be a short script of what my experience was and which errors I encountered. Or see it as notes in the case that I ever have to do this again.\nI won’t give any links providing theoretical background, because I think everybody has different needs and any search engine should do a better job with this than me. There are tons of sources out there with different highlights, so just look around.\nCode Tutorial:\r\rhttps://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/\r\rThis is the only tutorial I could find for R, but there are more python versions available.\n\rSoftware prerequisites:\rThe cluster I work on provides modules that can be easily loaded. In case of R it comes with no packages at all and in case of python only with some base modules. Therefore the next two links will explain how to install those:\nFor R:\n\rhttps://thecoatlessprofessor.com/programming/r/working-with-r-on-a-cluster/\r\rThey key part starts at “Setup a local R library for installing and loading R Packages” but the section “Passing arguments” is also very interesting, if you want to launch you script with some parameters, e.g. if you want to specify different learning rates, but don’t want to copy \u0026amp; paste multiple scripts to run them parallel.\nFor python:\n\rhttps://www.pik-potsdam.de/members/linstead/guides/python-on-the-cluster/installing-your-own-python-modules-on-the-cluster\r\rI used this tutorial with “Option 2. virtualenv and pip”. The instructions are deprecated, because I think they favor a conda virtualenv over a python virtualenv now. I have no knowledge to judge the appropriateness of either, but the python virtualenv worked great for me and was easy to install and understand.\n\rCUDA and Tensorflow (and cuDNN):\rThis is only relevant if you want to train on a GPU. If you only train on a CPU just install the newest version of tensorflow\nThis gave the most troubles. You want to be very accurate about the versions of all three and have them matched, otherwise you enter a whole new world of frustration. Here is a list of which versions are compatible:\n\rhttps://www.tensorflow.org/install/source#tested_build_configurations\r\rCUDA came as a module on my cluster, and I was able to choose different versions. I chose the 10.1 version. Installing tensorflow was trouble-less using the python virtualenv and pip. CuDNN took me a while to figure out, because it wasn’t installed with the CUDA version on the cluster. I assume this is due to some license issues, the reason being you have to apply for the NVIDIA developer program to download them. The easiest and non-invasive way to include the cuDNN files I found in an Stack Overflow thread after banging my head against a wall for a whole day:\n\rhttps://stackoverflow.com/questions/41494585/setting-ld-library-path-from-inside-r\r\rYou will know that you have to perform this step if you see an error message like this:\nImportError: libcudnn.so.7: cannot open shared object file: No such file or directory\rBasically you want to include every file with dyn.load() that tensorflow is complaining about. For me it was only this libcudnn.so.7 file.\n\rKeras:\rKeras for R itself worked without much troubles, the only bug I also encountered was the mysterious and strangely appearing and disappearing\n Error in py_get_attr_impl(x, name, silent) : AttributeError: module \u0026#39;kerastools\u0026#39; has no attribute \u0026#39;progbar\u0026#39;\rbug. This apparently is a real bug and fixed in the new version of keras:\n\rhttps://github.com/rstudio/keras/issues/992\r\rFor the time being you can either install the development version of keras, which I was hesitant about, not wanting to introduce more dependency issues, or just run\ntry(k_constant(1), silent=TRUE)\rtry(k_constant(1), silent=TRUE)\rThis will trigger the error on the first try and apparently load whatever is needed so it works on the second try. Again this is a bug that will be fixed in the upcoming version (current version: 2.2.5.0)\n\rSaving, loading, and predicting the BERT model:\rThere are different means of saving and loading a model with keras:\n\rsave_model_tf(): This function saves the model as multiple files in a folder and you have to specify the only the folder, if you want to load the model. I had no luck with this. There always was an error message when I tried to load the model but i also didn’t try to hard, as I found another way that worked for me.\rsave_model_weights_tf/hdf5(): As far as I understand, this only saves the matrix with the weights, so you need to specify and compile the whole model as it was trained, when you want to load weights into the model.\rsave_model_hdf5(): This was the function I ended up using, although it also wasn’t very straight forward. It saves the model in a single file (or multiple, depending on the size). The slightly finicky details are as follows:\r\rYou want to load the model with the following command:\nbert \u0026lt;- keras::load_model_hdf5(\u0026quot;path/to/file.hdf5\u0026quot;),\rcustom_objects = k_bert$get_custom_objects())\rTherefore, you need to load the model (which you have to do anyway to tokenize your to be predicted data). All the code to load the model you can find in the BERT for R tutorial. As BERT uses custom layers not included with keras, you have to pass them as custom objects to the load function. Otherwise this error will appear:\nError in py_call_impl(callable, dots$args, dots$keywords) : ValueError: Unknown layer: TokenEmbedding \rThen, at least for me, the model also failed to auto-compile on load, so I had to compile it by hand. Fortunately this worked by the same means as in the training tutorial. You have to specify the target length, learning rate, batch size, and epochs, but that it plain worked for me.\nc(decay_steps, warmup_steps) %\u0026lt;-% k_bert$calc_train_steps(\rtargetsPred %\u0026gt;% length(),\rbatch_size=bch_size,\repochs=epochs\r)\rbert %\u0026gt;% compile(\rk_bert$AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=learning_rate),\rloss = \u0026#39;binary_crossentropy\u0026#39;,\rmetrics = \u0026#39;accuracy\u0026#39;\r)\rThe data you want to predict needs to be tokenized as well. To achieve this, just repeat the same steps as with the training data, until the concat list is made. For the k_bert$calc_train_steps() function the length of the data must be specified. I just generated a LABEL_COLUMN in my dataframe with NAs and kept the rest of the code the same. If you do it this way, you also don’t have to modify the tokenize_fun() function. For my convenience I modified the function anyway, to accept two strings for the data and the label column:\ntokenize_fun = function(dataset, DATA_COLUMN, LABEL_COLUMN) {\rc(indices, target, segments) %\u0026lt;-% list(list(),list(),list())\rpb = txtProgressBar(min = 0, max = nrow(dataset), initial = 0,style = 3) for (i in 1:nrow(dataset)) {\rsetTxtProgressBar(pb,i)\rc(indices_tok, segments_tok) %\u0026lt;-% tokenizer$encode(dataset[[DATA_COLUMN]][i], max_len=seq_length)\rindices = indices %\u0026gt;% append(list(as.matrix(indices_tok)))\rtarget = target %\u0026gt;% append(dataset[[LABEL_COLUMN]][i])\rsegments = segments %\u0026gt;% append(list(as.matrix(segments_tok)))\r}\rreturn(list(indices, segments, target))\r}\rGenerating predictions from the model is quite simple, just use the predict() function with the model, and the tokenized data:\npredict(bert, concat, verbose = 1)\rThe regular predict() function has no verbosity, so there is no default. I highly recommend setting it as prediction might take a while. You might even want to do the prediction on a cluster as well.\n\rSome advice for using a cluster:\rThis is probably some pretty natural stuff for anyone who already worked with a cluster, but as this was my first experience with one, I want to state a single thing that I wish I had known earlier:\nI am not sure, whether every cluster offers this functionality, but at my place I was able to queue an interactive session instead of a job. After some waiting, this provides you with a shell interface to a node. Troubleshooting is so much easier if you don’t have to wait an hour for your job to be scheduled and then see it fail within seconds because you made a typo. Just run your script with Rscript and don’t forget to include many\ncat(paste(Sys.time(), \u0026quot;Loading some data or whatever...\\n\u0026quot;))\rto see where your stuff fails. And it will fail.\n\r","date":1583712000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583712000,"objectID":"42265f8761c9531f871902f249cd3ba3","permalink":"https://jadenecke.github.io/2020/03/09/training-a-bidirectional-encoder-representations-from-transformers-bert-on-a-cluster-with-r-links-and-tips/","publishdate":"2020-03-09T00:00:00Z","relpermalink":"/2020/03/09/training-a-bidirectional-encoder-representations-from-transformers-bert-on-a-cluster-with-r-links-and-tips/","section":"post","summary":"This will merely be a short script of what my experience was and which errors I encountered. Or see it as notes in the case that I ever have to do this again.\nI won’t give any links providing theoretical background, because I think everybody has different needs and any search engine should do a better job with this than me. There are tons of sources out there with different highlights, so just look around.","tags":["R","NLP","BERT","CLUSTER"],"title":"Training a Bidirectional Encoder Representations from Transformers (BERT) on a Cluster with R: Links and tips","type":"post"}]